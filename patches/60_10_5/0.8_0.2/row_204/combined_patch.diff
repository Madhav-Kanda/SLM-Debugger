--- a/decoupled/60/0.8_0.2/204/scikit-learn_scikit-learn/sklearn/calibration.py
+++ b/decoupled/60/0.8_0.2/204/scikit-learn_scikit-learn/sklearn/calibration.py
@@ -1125,66 +1125,36 @@
         self.estimator_name = estimator_name

         self.pos_label = pos_label

 

-    def plot(self, *, ax=None, name=None, ref_line=True, **kwargs):

-        """Plot visualization.

-

-        Extra keyword arguments will be passed to

-        :func:`matplotlib.pyplot.plot`.

-

-        Parameters

-        ----------

-        ax : Matplotlib Axes, default=None

-            Axes object to plot on. If `None`, a new figure and axes is

-            created.

-

-        name : str, default=None

-            Name for labeling curve. If `None`, use `estimator_name` if

-            not `None`, otherwise no labeling is shown.

-

-        ref_line : bool, default=True

-            If `True`, plots a reference line representing a perfectly

-            calibrated classifier.

-

-        **kwargs : dict

-            Keyword arguments to be passed to :func:`matplotlib.pyplot.plot`.

-

-        Returns

-        -------

-        display : :class:`~sklearn.calibration.CalibrationDisplay`

-            Object that stores computed values.

-        """

-        check_matplotlib_support("CalibrationDisplay.plot")

-        import matplotlib.pyplot as plt

-

-        if ax is None:

-            fig, ax = plt.subplots()

-

-        name = self.estimator_name if name is None else name

-        info_pos_label = (

-            f"(Positive class: {self.pos_label})" if self.pos_label is not None else ""

-        )

-

-        line_kwargs = {}

-        if name is not None:

-            line_kwargs["label"] = name

-        line_kwargs.update(**kwargs)

-

-        ref_line_label = "Perfectly calibrated"

-        existing_ref_line = ref_line_label in ax.get_legend_handles_labels()[1]

-        if ref_line and not existing_ref_line:

-            ax.plot([0, 1], [0, 1], "k:", label=ref_line_label)

-        self.line_ = ax.plot(self.prob_pred, self.prob_true, "s-", **line_kwargs)[0]

-

-        # We always have to show the legend for at least the reference line

-        ax.legend(loc="lower right")

-

-        xlabel = f"Mean predicted probability {info_pos_label}"

-        ylabel = f"Fraction of positives {info_pos_label}"

-        ax.set(xlabel=xlabel, ylabel=ylabel)

-

-        self.ax_ = ax

-        self.figure_ = ax.figure

+from sklearn.compose import ColumnTransformer

+from sklearn.impute import SimpleImputer

+from sklearn.pipeline import Pipeline

+from sklearn.preprocessing import RobustScaler

+import pandas as pd

+from sklearn.base import TransformerMixin

+

+class PassthroughTransformer(TransformerMixin):

+    """Transformer that simply returns the input data."""

+    def fit(self, X, y=None):

         return self

+

+    def transform(self, X):

+        return X

+

+# Modify the ColumnTransformer to handle the case where a transformer has no features

+X = pd.DataFrame(data=[[1.0, 2.0, 3.0, 4.0], [4, 2, 2, 5]],

+                 columns=["a", "b", "c", "d"])

+y = np.array([0, 1])

+categorical_features = []

+numerical_features = ["a", "b", "c"]

+model_preprocessing = ("preprocessing",

+                       ColumnTransformer([

+                           ('categorical', PassthroughTransformer(), categorical_features),

+                           ('numerical', Pipeline([("scaler", RobustScaler()),

+                                                   ("imputer", SimpleImputer(strategy="median"))

+                                                   ]), numerical_features),

+                       ], remainder='drop'))

+pipeline = Pipeline([model_preprocessing, ("classifier", LGBMClassifier())]).set_output(transform="pandas")

+pipeline.fit(X, y)

 

     @classmethod

     def from_estimator(


--- a/decoupled/60/0.8_0.2/204/scikit-learn_scikit-learn/sklearn/calibration.py
+++ b/decoupled/60/0.8_0.2/204/scikit-learn_scikit-learn/sklearn/calibration.py
@@ -1313,116 +1313,120 @@
         )

 

     @classmethod

-    def from_predictions(

-        cls,

-        y_true,

-        y_prob,

-        *,

-        n_bins=5,

-        strategy="uniform",

-        pos_label=None,

-        name=None,

-        ref_line=True,

-        ax=None,

-        **kwargs,

-    ):

-        """Plot calibration curve using true labels and predicted probabilities.

-

-        Calibration curve, also known as reliability diagram, uses inputs

-        from a binary classifier and plots the average predicted probability

-        for each bin against the fraction of positive classes, on the

-        y-axis.

-

-        Extra keyword arguments will be passed to

-        :func:`matplotlib.pyplot.plot`.

-

-        Read more about calibration in the :ref:`User Guide <calibration>` and

-        more about the scikit-learn visualization API in :ref:`visualizations`.

-

-        .. versionadded:: 1.0

-

-        Parameters

-        ----------

-        y_true : array-like of shape (n_samples,)

-            True labels.

-

-        y_prob : array-like of shape (n_samples,)

-            The predicted probabilities of the positive class.

-

-        n_bins : int, default=5

-            Number of bins to discretize the [0, 1] interval into when

-            calculating the calibration curve. A bigger number requires more

-            data.

-

-        strategy : {'uniform', 'quantile'}, default='uniform'

-            Strategy used to define the widths of the bins.

-

-            - `'uniform'`: The bins have identical widths.

-            - `'quantile'`: The bins have the same number of samples and depend

-              on predicted probabilities.

-

-        pos_label : str or int, default=None

-            The positive class when computing the calibration curve.

-            By default, `estimators.classes_[1]` is considered as the

-            positive class.

-

-            .. versionadded:: 1.1

-

-        name : str, default=None

-            Name for labeling curve.

-

-        ref_line : bool, default=True

-            If `True`, plots a reference line representing a perfectly

-            calibrated classifier.

-

-        ax : matplotlib axes, default=None

-            Axes object to plot on. If `None`, a new figure and axes is

-            created.

-

-        **kwargs : dict

-            Keyword arguments to be passed to :func:`matplotlib.pyplot.plot`.

-

-        Returns

-        -------

-        display : :class:`~sklearn.calibration.CalibrationDisplay`.

-            Object that stores computed values.

-

-        See Also

-        --------

-        CalibrationDisplay.from_estimator : Plot calibration curve using an

-            estimator and data.

-

-        Examples

-        --------

-        >>> import matplotlib.pyplot as plt

-        >>> from sklearn.datasets import make_classification

-        >>> from sklearn.model_selection import train_test_split

-        >>> from sklearn.linear_model import LogisticRegression

-        >>> from sklearn.calibration import CalibrationDisplay

-        >>> X, y = make_classification(random_state=0)

-        >>> X_train, X_test, y_train, y_test = train_test_split(

-        ...     X, y, random_state=0)

-        >>> clf = LogisticRegression(random_state=0)

-        >>> clf.fit(X_train, y_train)

-        LogisticRegression(random_state=0)

-        >>> y_prob = clf.predict_proba(X_test)[:, 1]

-        >>> disp = CalibrationDisplay.from_predictions(y_test, y_prob)

-        >>> plt.show()

-        """

-        method_name = f"{cls.__name__}.from_estimator"

-        check_matplotlib_support(method_name)

-

-        prob_true, prob_pred = calibration_curve(

-            y_true, y_prob, n_bins=n_bins, strategy=strategy, pos_label=pos_label

-        )

-        name = "Classifier" if name is None else name

-        pos_label = _check_pos_label_consistency(pos_label, y_true)

-

-        disp = cls(

-            prob_true=prob_true,

-            prob_pred=prob_pred,

-            y_prob=y_prob,

-            estimator_name=name,

-            pos_label=pos_label,

-        )

-        return disp.plot(ax=ax, ref_line=ref_line, **kwargs)

+from sklearn.compose import ColumnTransformer

+from sklearn.impute import SimpleImputer

+from sklearn.pipeline import Pipeline

+from sklearn.preprocessing import RobustScaler

+

+def from_predictions(

+    cls,

+    y_true,

+    y_prob,

+    *,

+    n_bins=5,

+    strategy="uniform",

+    pos_label=None,

+    name=None,

+    ref_line=True,

+    ax=None,

+    **kwargs,

+):

+    """Plot calibration curve using true labels and predicted probabilities.

+

+    Calibration curve, also known as reliability diagram, uses inputs

+    from a binary classifier and plots the average predicted probability

+    for each bin against the fraction of positive classes, on the y-axis.

+

+    Extra keyword arguments will be passed to

+    :func:`matplotlib.pyplot.plot`.

+

+    Read more about calibration in the :ref:`User Guide <calibration>` and

+    more about the scikit-learn visualization API in :ref:`visualizations`.

+

+    .. versionadded:: 1.0

+

+    Parameters

+    ----------

+    y_true : array-like of shape (n_samples,)

+        True labels.

+

+    y_prob : array-like of shape (n_samples,)

+        The predicted probabilities of the positive class.

+

+    n_bins : int, default=5

+        Number of bins to discretize the [0, 1] interval into when

+        calculating the calibration curve. A bigger number requires more

+        data.

+

+    strategy : {'uniform', 'quantile'}, default='uniform'

+        Strategy used to define the widths of the bins.

+

+        - `'uniform'`: The bins have identical widths.

+        - `'quantile'`: The bins have the same number of samples and depend

+          on predicted probabilities.

+

+    pos_label : str or int, default=None

+        The positive class when computing the calibration curve.

+        By default, `estimators.classes_[1]` is considered as the

+        positive class.

+

+        .. versionadded:: 1.1

+

+    name : str, default=None

+        Name for labeling curve.

+

+    ref_line : bool, default=True

+        If `True`, plots a reference line representing a perfectly

+        calibrated classifier.

+

+    ax : matplotlib axes, default=None

+        Axes object to plot on. If `None`, a new figure and axes is

+        created.

+

+    **kwargs : dict

+        Keyword arguments to be passed to :func:`matplotlib.pyplot.plot`.

+

+    Returns

+    -------

+    display : :class:`~sklearn.calibration.CalibrationDisplay`.

+        Object that stores computed values.

+

+    See Also

+    --------

+    CalibrationDisplay.from_estimator : Plot calibration curve using an

+        estimator and data.

+

+    Examples

+    --------

+    >>> import matplotlib.pyplot as plt

+    >>> from sklearn.datasets import make_classification

+    >>> from sklearn.model_selection import train_test_split

+    >>> from sklearn.linear_model import LogisticRegression

+    >>> from sklearn.calibration import CalibrationDisplay

+    >>> X, y = make_classification(random_state=0)

+    >>> X_train, X_test, y_train, y_test = train_test_split(

+    ...     X, y, random_state=0)

+    >>> clf = LogisticRegression(random_state=0)

+    >>> clf.fit(X_train, y_train)

+    LogisticRegression(random_state=0)

+    >>> y_prob = clf.predict_proba(X_test)[:, 1]

+    >>> disp = CalibrationDisplay.from_predictions(y_test, y_prob)

+    >>> plt.show()

+    """

+    method_name = f"{cls.__name__}.from_estimator"

+    check_matplotlib_support(method_name)

+

+    prob_true, prob_pred = calibration_curve(

+        y_true, y_prob, n_bins=n_bins, strategy=strategy, pos_label=pos_label

+    )

+    name = "Classifier" if name is None else name

+    pos_label = _check_pos_label_consistency(pos_label, y_true)

+

+    disp = cls(

+        prob_true=prob_true,

+        prob_pred=prob_pred,

+        y_prob=y_prob,

+        estimator_name=name,

+        pos_label=pos_label,

+    )

+    return disp.plot(ax=ax, ref_line=ref_line, **kwargs)


--- a/decoupled/60/0.8_0.2/204/scikit-learn_scikit-learn/sklearn/calibration.py
+++ b/decoupled/60/0.8_0.2/204/scikit-learn_scikit-learn/sklearn/calibration.py
@@ -1187,130 +1187,133 @@
         return self

 

     @classmethod

-    def from_estimator(

-        cls,

-        estimator,

-        X,

+def from_estimator(

+    cls,

+    estimator,

+    X,

+    y,

+    *,

+    n_bins=5,

+    strategy="uniform",

+    pos_label=None,

+    name=None,

+    ref_line=True,

+    ax=None,

+    **kwargs,

+):

+    """Plot calibration curve using a binary classifier and data.

+

+    A calibration curve, also known as a reliability diagram, uses inputs

+    from a binary classifier and plots the average predicted probability

+    for each bin against the fraction of positive classes, on the

+    y-axis.

+

+    Extra keyword arguments will be passed to

+    :func:`matplotlib.pyplot.plot`.

+

+    Read more about calibration in the :ref:`User Guide <calibration>` and

+    more about the scikit-learn visualization API in :ref:`visualizations`.

+

+    .. versionadded:: 1.0

+

+    Parameters

+    ----------

+    estimator : estimator instance

+        Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`

+        in which the last estimator is a classifier. The classifier must

+        have a :term:`predict_proba` method.

+

+    X : {array-like, sparse matrix} of shape (n_samples, n_features)

+        Input values.

+

+    y : array-like of shape (n_samples,)

+        Binary target values.

+

+    n_bins : int, default=5

+        Number of bins to discretize the [0, 1] interval into when

+        calculating the calibration curve. A bigger number requires more

+        data.

+

+    strategy : {'uniform', 'quantile'}, default='uniform'

+        Strategy used to define the widths of the bins.

+

+        - `'uniform'`: The bins have identical widths.

+        - `'quantile'`: The bins have the same number of samples and depend

+          on predicted probabilities.

+

+    pos_label : str or int, default=None

+        The positive class when computing the calibration curve.

+        By default, `estimators.classes_[1]` is considered as the

+        positive class.

+

+        .. versionadded:: 1.1

+

+    name : str, default=None

+        Name for labeling curve. If `None`, the name of the estimator is

+        used.

+

+    ref_line : bool, default=True

+        If `True`, plots a reference line representing a perfectly

+        calibrated classifier.

+

+    ax : matplotlib axes, default=None

+        Axes object to plot on. If `None`, a new figure and axes is

+        created.

+

+    **kwargs : dict

+        Keyword arguments to be passed to :func:`matplotlib.pyplot.plot`.

+

+    Returns

+    -------

+    display : :class:`~sklearn.calibration.CalibrationDisplay`.

+        Object that stores computed values.

+

+    See Also

+    --------

+    CalibrationDisplay.from_predictions : Plot calibration curve using true

+        and predicted labels.

+

+    Examples

+    --------

+    >>> import matplotlib.pyplot as plt

+    >>> from sklearn.datasets import make_classification

+    >>> from sklearn.model_selection import train_test_split

+    >>> from sklearn.linear_model import LogisticRegression

+    >>> from sklearn.calibration import CalibrationDisplay

+    >>> X, y = make_classification(random_state=0)

+    >>> X_train, X_test, y_train, y_test = train_test_split(

+    ...     X, y, random_state=0)

+    >>> clf = LogisticRegression(random_state=0)

+    >>> clf.fit(X_train, y_train)

+    LogisticRegression(random_state=0)

+    >>> disp = CalibrationDisplay.from_estimator(clf, X_test, y_test)

+    >>> plt.show()

+    """

+    method_name = f"{cls.__name__}.from_estimator"

+    check_matplotlib_support(method_name)

+

+    if not is_classifier(estimator):

+        raise ValueError("'estimator' should be a fitted classifier.")

+

+    y_prob, pos_label = _get_response(

+        X, estimator, response_method="predict_proba", pos_label=pos_label

+    )

+

+    name = name if name is not None else estimator.__class__.__name__

+    return cls.from_predictions(

         y,

-        *,

-        n_bins=5,

-        strategy="uniform",

-        pos_label=None,

-        name=None,

-        ref_line=True,

-        ax=None,

+        y_prob,

+        n_bins=n_bins,

+        strategy=strategy,

+        pos_label=pos_label,

+        name=name,

+        ref_line=ref_line,

+        ax=ax,

         **kwargs,

-    ):

-        """Plot calibration curve using a binary classifier and data.

-

-        A calibration curve, also known as a reliability diagram, uses inputs

-        from a binary classifier and plots the average predicted probability

-        for each bin against the fraction of positive classes, on the

-        y-axis.

-

-        Extra keyword arguments will be passed to

-        :func:`matplotlib.pyplot.plot`.

-

-        Read more about calibration in the :ref:`User Guide <calibration>` and

-        more about the scikit-learn visualization API in :ref:`visualizations`.

-

-        .. versionadded:: 1.0

-

-        Parameters

-        ----------

-        estimator : estimator instance

-            Fitted classifier or a fitted :class:`~sklearn.pipeline.Pipeline`

-            in which the last estimator is a classifier. The classifier must

-            have a :term:`predict_proba` method.

-

-        X : {array-like, sparse matrix} of shape (n_samples, n_features)

-            Input values.

-

-        y : array-like of shape (n_samples,)

-            Binary target values.

-

-        n_bins : int, default=5

-            Number of bins to discretize the [0, 1] interval into when

-            calculating the calibration curve. A bigger number requires more

-            data.

-

-        strategy : {'uniform', 'quantile'}, default='uniform'

-            Strategy used to define the widths of the bins.

-

-            - `'uniform'`: The bins have identical widths.

-            - `'quantile'`: The bins have the same number of samples and depend

-              on predicted probabilities.

-

-        pos_label : str or int, default=None

-            The positive class when computing the calibration curve.

-            By default, `estimators.classes_[1]` is considered as the

-            positive class.

-

-            .. versionadded:: 1.1

-

-        name : str, default=None

-            Name for labeling curve. If `None`, the name of the estimator is

-            used.

-

-        ref_line : bool, default=True

-            If `True`, plots a reference line representing a perfectly

-            calibrated classifier.

-

-        ax : matplotlib axes, default=None

-            Axes object to plot on. If `None`, a new figure and axes is

-            created.

-

-        **kwargs : dict

-            Keyword arguments to be passed to :func:`matplotlib.pyplot.plot`.

-

-        Returns

-        -------

-        display : :class:`~sklearn.calibration.CalibrationDisplay`.

-            Object that stores computed values.

-

-        See Also

-        --------

-        CalibrationDisplay.from_predictions : Plot calibration curve using true

-            and predicted labels.

-

-        Examples

-        --------

-        >>> import matplotlib.pyplot as plt

-        >>> from sklearn.datasets import make_classification

-        >>> from sklearn.model_selection import train_test_split

-        >>> from sklearn.linear_model import LogisticRegression

-        >>> from sklearn.calibration import CalibrationDisplay

-        >>> X, y = make_classification(random_state=0)

-        >>> X_train, X_test, y_train, y_test = train_test_split(

-        ...     X, y, random_state=0)

-        >>> clf = LogisticRegression(random_state=0)

-        >>> clf.fit(X_train, y_train)

-        LogisticRegression(random_state=0)

-        >>> disp = CalibrationDisplay.from_estimator(clf, X_test, y_test)

-        >>> plt.show()

-        """

-        method_name = f"{cls.__name__}.from_estimator"

-        check_matplotlib_support(method_name)

-

-        if not is_classifier(estimator):

-            raise ValueError("'estimator' should be a fitted classifier.")

-

-        y_prob, pos_label = _get_response(

-            X, estimator, response_method="predict_proba", pos_label=pos_label

-        )

-

-        name = name if name is not None else estimator.__class__.__name__

-        return cls.from_predictions(

-            y,

-            y_prob,

-            n_bins=n_bins,

-            strategy=strategy,

-            pos_label=pos_label,

-            name=name,

-            ref_line=ref_line,

-            ax=ax,

-            **kwargs,

-        )

+    )

+

+# Example usage

+X = pd.DataFrame(data=[[1

 

     @classmethod

     def from_predictions(


--- a/decoupled/60/0.8_0.2/204/scikit-learn_scikit-learn/sklearn/gaussian_process/_gpr.py
+++ b/decoupled/60/0.8_0.2/204/scikit-learn_scikit-learn/sklearn/gaussian_process/_gpr.py
@@ -203,7 +203,7 @@
         self.copy_X_train = copy_X_train

         self.random_state = random_state

 

-    def fit(self, X, y):

+def fit(self, X, y):

         """Fit Gaussian process regression model.

 

         Parameters

@@ -312,30 +312,7 @@
             self.log_marginal_likelihood_value_ = -np.min(lml_values)

         else:

             self.log_marginal_likelihood_value_ = self.log_marginal_likelihood(

-                self.kernel_.theta, clone_kernel=False

-            )

-

-        # Precompute quantities required for predictions which are independent

-        # of actual query points

-        # Alg. 2.1, page 19, line 2 -> L = cholesky(K + sigma^2 I)

-        K = self.kernel_(self.X_train_)

-        K[np.diag_indices_from(K)] += self.alpha

-        try:

-            self.L_ = cholesky(K, lower=GPR_CHOLESKY_LOWER, check_finite=False)

-        except np.linalg.LinAlgError as exc:

-            exc.args = (

-                f"The kernel, {self.kernel_}, is not returning a positive "

-                "definite matrix. Try gradually increasing the 'alpha' "

-                "parameter of your GaussianProcessRegressor estimator.",

-            ) + exc.args

-            raise

-        # Alg 2.1, page 19, line 3 -> alpha = L^T \ (L \ y)

-        self.alpha_ = cho_solve(

-            (self.L_, GPR_CHOLESKY_LOWER),

-            self.y_train_,

-            check_finite=False,

-        )

-        return self

+                self.kernel_.theta, clone_kernel

 

     def predict(self, X, return_std=False, return_cov=False):

         """Predict using the Gaussian process regression model.


--- a/decoupled/60/0.8_0.2/204/scikit-learn_scikit-learn/sklearn/decomposition/_fastica.py
+++ b/decoupled/60/0.8_0.2/204/scikit-learn_scikit-learn/sklearn/decomposition/_fastica.py
@@ -527,7 +527,7 @@
         self.whiten_solver = whiten_solver

         self.random_state = random_state

 

-    def _fit_transform(self, X, compute_sources=False):

+def _fit_transform(self, X, compute_sources=False):

         """Fit the model.

 

         Parameters

@@ -607,7 +607,7 @@
             # Whitening and preprocessing by PCA

             if self.whiten_solver == "eigh":

                 # Faster when num_samples >> n_features

-                d, u = linalg.eigh(XT.dot(X))

+                d, u = linalg.eigh(XT.dot(XT.T))

                 sort_indices = np.argsort(d)[::-1]

                 eps = np.finfo(d.dtype).eps

                 degenerate_idx = d < eps

@@ -631,68 +631,7 @@
             X1 = np.dot(K, XT)

             # see (13.6) p.267 Here X1 is white and data

             # in X has been projected onto a subspace by PCA

-            X1 *= np.sqrt(n_samples)

-        else:

-            # X must be casted to floats to avoid typing issues with numpy

-            # 2.0 and the line below

-            X1 = as_float_array(XT, copy=False)  # copy has been taken care of

-

-        w_init = self.w_init

-        if w_init is None:

-            w_init = np.asarray(

-                random_state.normal(size=(n_components, n_components)), dtype=X1.dtype

-            )

-

-        else:

-            w_init = np.asarray(w_init)

-            if w_init.shape != (n_components, n_components):

-                raise ValueError(

-                    "w_init has invalid shape -- should be %(shape)s"

-                    % {"shape": (n_components, n_components)}

-                )

-

-        kwargs = {

-            "tol": self.tol,

-            "g": g,

-            "fun_args": fun_args,

-            "max_iter": self.max_iter,

-            "w_init": w_init,

-        }

-

-        if self.algorithm == "parallel":

-            W, n_iter = _ica_par(X1, **kwargs)

-        elif self.algorithm == "deflation":

-            W, n_iter = _ica_def(X1, **kwargs)

-        del X1

-

-        self.n_iter_ = n_iter

-

-        if compute_sources:

-            if self._whiten:

-                S = np.linalg.multi_dot([W, K, XT]).T

-            else:

-                S = np.dot(W, XT).T

-        else:

-            S = None

-

-        if self._whiten:

-            if self._whiten == "unit-variance":

-                if not compute_sources:

-                    S = np.linalg.multi_dot([W, K, XT]).T

-                S_std = np.std(S, axis=0, keepdims=True)

-                S /= S_std

-                W /= S_std.T

-

-            self.components_ = np.dot(W, K)

-            self.mean_ = X_mean

-            self.whitening_ = K

-        else:

-            self.components_ = W

-

-        self.mixing_ = linalg.pinv(self.components_, check_finite=False)

-        self._unmixing = W

-

-        return S

+            X1 *=

 

     def fit_transform(self, X, y=None):

         """Fit the model and recover the sources from X.


