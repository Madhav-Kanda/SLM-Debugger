--- a/decoupled/60/0.8_0.2/196/scikit-learn_scikit-learn/sklearn/utils/estimator_checks.py
+++ b/decoupled/60/0.8_0.2/196/scikit-learn_scikit-learn/sklearn/utils/estimator_checks.py
@@ -574,6 +574,19 @@
 

 

 @ignore_warnings(category=(DeprecationWarning, FutureWarning))

+from sklearn.utils.estimator_checks import check_estimator

+from sklearn.utils.validation import has_fit_parameter

+from sklearn.utils import check_X_y

+from sklearn.utils import column_or_1d

+from sklearn.base import clone

+import numpy as np

+from sklearn.datasets import load_iris

+from sklearn.linear_model import LogisticRegression

+from sklearn.ensemble import RandomForestClassifier

+from sklearn.utils.estimator_checks import check_estimator

+from sklearn.utils.validation import check_is_fitted

+from sklearn.utils.validation import _check_sample_weight

+

 def check_sample_weights_list(name, estimator_orig):

     # check that estimators will accept a 'sample_weight' parameter of

     # type list in the 'fit' function.

@@ -587,6 +600,23 @@
         sample_weight = [3] * 10

         # Test that estimators don't raise any exception

         estimator.fit(X, y, sample_weight=sample_weight)

+

+def fit_voting_classifier_with_sample_weights(voter, X, y, sample_weight):

+    # Filter out None estimators before fitting

+    non_none_estimators = {name: est for name, est in voter.estimators_ if est is not None}

+    voter.estimators_ = list(non_none_estimators.items())

+    voter.fit(X, y, sample_weight=sample_weight)

+    voter.estimators_ = list(voter.estimators_)

+    return voter

+

+X, y = load_iris(return_X_y=True)

+voter = VotingClassifier(

+    estimators=[('lr', LogisticRegression()),

+                ('rf', RandomForestClassifier())]

+)

+voter.fit(X, y, sample_weight=np.ones(y.shape))

+voter.set_params(lr=None)

+voter = fit_voting_classifier_with_sample_weights(voter, X, y, sample_weight=np.ones(y.shape))

 

 

 @ignore_warnings(category=(DeprecationWarning, FutureWarning))
