--- a/decoupled/60/0.8_0.2/198/scikit-learn_scikit-learn/sklearn/model_selection/_validation.py
+++ b/decoupled/60/0.8_0.2/198/scikit-learn_scikit-learn/sklearn/model_selection/_validation.py
@@ -713,80 +713,7 @@
     Notes

     -----

     In the case that one or more classes are absent in a training portion, a

-    default score needs to be assigned to all instances for that class if

-    ``method`` produces columns per class, as in {'decision_function',

-    'predict_proba', 'predict_log_proba'}.  For ``predict_proba`` this value is

-    0.  In order to ensure finite output, we approximate negative infinity by

-    the minimum finite float value for the dtype in other cases.

-

-    Examples

-    --------

-    >>> from sklearn import datasets, linear_model

-    >>> from sklearn.model_selection import cross_val_predict

-    >>> diabetes = datasets.load_diabetes()

-    >>> X = diabetes.data[:150]

-    >>> y = diabetes.target[:150]

-    >>> lasso = linear_model.Lasso()

-    >>> y_pred = cross_val_predict(lasso, X, y, cv=3)

-    """

-    X, y, groups = indexable(X, y, groups)

-

-    cv = check_cv(cv, y, classifier=is_classifier(estimator))

-

-    # If classification methods produce multiple columns of output,

-    # we need to manually encode classes to ensure consistent column ordering.

-    encode = method in ['decision_function', 'predict_proba',

-                        'predict_log_proba']

-    if encode:

-        y = np.asarray(y)

-        if y.ndim == 1:

-            le = LabelEncoder()

-            y = le.fit_transform(y)

-        elif y.ndim == 2:

-            y_enc = np.zeros_like(y, dtype=np.int)

-            for i_label in range(y.shape[1]):

-                y_enc[:, i_label] = LabelEncoder().fit_transform(y[:, i_label])

-            y = y_enc

-

-    # We clone the estimator to make sure that all the folds are

-    # independent, and that it is pickle-able.

-    parallel = Parallel(n_jobs=n_jobs, verbose=verbose,

-                        pre_dispatch=pre_dispatch)

-    prediction_blocks = parallel(delayed(_fit_and_predict)(

-        clone(estimator), X, y, train, test, verbose, fit_params, method)

-        for train, test in cv.split(X, y, groups))

-

-    # Concatenate the predictions

-    predictions = [pred_block_i for pred_block_i, _ in prediction_blocks]

-    test_indices = np.concatenate([indices_i

-                                   for _, indices_i in prediction_blocks])

-

-    if not _check_is_permutation(test_indices, _num_samples(X)):

-        raise ValueError('cross_val_predict only works for partitions')

-

-    inv_test_indices = np.empty(len(test_indices), dtype=int)

-    inv_test_indices[test_indices] = np.arange(len(test_indices))

-

-    if sp.issparse(predictions[0]):

-        predictions = sp.vstack(predictions, format=predictions[0].format)

-    elif encode and isinstance(predictions[0], list):

-        # `predictions` is a list of method outputs from each fold.

-        # If each of those is also a list, then treat this as a

-        # multioutput-multiclass task. We need to separately concatenate

-        # the method outputs for each label into an `n_labels` long list.

-        n_labels = y.shape[1]

-        concat_pred = []

-        for i_label in range(n_labels):

-            label_preds = np.concatenate([p[i_label] for p in predictions])

-            concat_pred.append(label_preds)

-        predictions = concat_pred

-    else:

-        predictions = np.concatenate(predictions)

-

-    if isinstance(predictions, list):

-        return [p[inv_test_indices] for p in predictions]

-    else:

-        return predictions[inv_test_indices]

+    default score needs to be assigned to all instances for

 

 

 def _fit_and_predict(estimator, X, y, train, test, verbose, fit_params,
