--- a/decoupled/60/0.8_0.2/174/pytest-dev_pytest/src/_pytest/assertion/util.py
+++ b/decoupled/60/0.8_0.2/174/pytest-dev_pytest/src/_pytest/assertion/util.py
@@ -17,20 +17,19 @@
 _assertion_pass = None

 

 

-def format_explanation(explanation):

-    """This formats an explanation

-

-    Normally all embedded newlines are escaped, however there are

-    three exceptions: \n{, \n} and \n~.  The first two are intended

-    cover nested explanations, see function and attribute explanations

-    for examples (.visit_Call(), visit_Attribute()).  The last one is

-    for when one explanation needs to span multiple lines, e.g. when

-    displaying diffs.

-    """

-    explanation = explanation

-    lines = _split_explanation(explanation)

-    result = _format_lines(lines)

-    return "\n".join(result)

+import pytest

+import xmlrunner

+

+class CustomXMLTestRunner(xmlrunner.XMLTestRunner):

+    def make_suite(self, test):

+        suite = super().make_suite(test)

+        suite.attrib['hostname'] = socket.gethostname()

+        suite.attrib['timestamp'] = datetime.datetime.now().isoformat()

+        return suite

+

+# Example usage

+if __name__ == "__main__":

+    pytest.main(["--junit-xml=report.xml", "-rA", "-v"], plugins=[CustomXMLTestRunner()])

 

 

 def _split_explanation(explanation):


--- a/decoupled/60/0.8_0.2/174/pytest-dev_pytest/src/_pytest/debugging.py
+++ b/decoupled/60/0.8_0.2/174/pytest-dev_pytest/src/_pytest/debugging.py
@@ -159,19 +159,16 @@
 

             do_c = do_cont = do_continue

 

-            def do_quit(self, arg):

-                """Raise Exit outcome when quit command is used in pdb.

-

-                This is a bit of a hack - it would be better if BdbQuit

-                could be handled, but this would require to wrap the

-                whole pytest run, and adjust the report etc.

-                """

-                ret = super().do_quit(arg)

-

-                if cls._recursive_debug == 0:

-                    outcomes.exit("Quitting debugger")

-

-                return ret

+# pytest.ini or pyproject.toml

+[pytest]

+junit_family = xunit1

+junit_xml_output = tests/reports/junit.xml

+

+# Add custom properties to the testsuite element

+[pytest-junitreport]

+properties =

+    hostname: {{ env.HOSTNAME or "localhost" }}

+    timestamp: {{ time.strftime('%Y-%m-%dT%H:%M:%S') }}

 

             do_q = do_quit

             do_exit = do_quit


--- a/decoupled/60/0.8_0.2/174/pytest-dev_pytest/src/_pytest/assertion/util.py
+++ b/decoupled/60/0.8_0.2/174/pytest-dev_pytest/src/_pytest/assertion/util.py
@@ -33,21 +33,30 @@
     return "\n".join(result)

 

 

-def _split_explanation(explanation):

-    """Return a list of individual lines in the explanation

-

-    This will return a list of lines split on '\n{', '\n}' and '\n~'.

-    Any other newlines will be escaped and appear in the line as the

-    literal '\n' characters.

-    """

-    raw_lines = (explanation or "").split("\n")

-    lines = [raw_lines[0]]

-    for values in raw_lines[1:]:

-        if values and values[0] in ["{", "}", "~", ">"]:

-            lines.append(values)

-        else:

-            lines[-1] += "\\n" + values

-    return lines

+import datetime

+import os

+

+def generate_junit_xml_report(test_results):

+    hostname = os.uname().nodename

+    timestamp = datetime.datetime.now().isoformat()

+    

+    report = f'<?xml version="1.0" encoding="utf-8"?>\n<testsuite errors="{test_results["errors"]}" failures="{test_results["failures"]}" name="{test_results["name"]}" skipped="{test_results["skipped"]}" tests="{test_results["tests"]}" time="{test_results["time"]}" timestamp="{timestamp}" hostname="{hostname}">\n'

+    report += '  <properties>\n'

+    report += '    <property name="property1" value="value1"/>\n'

+    report += '    <property name="property2" value="value2"/>\n'

+    report += '  </properties>\n'

+    

+    for test in test_results["testcases"]:

+        report += f'  <testcase name="{test["name"]}" classname="{test["classname"]}" file="{test["file"]}" line="{test["line"]}" time="{test["time"]}">\n'

+        if test["status"] == "failure":

+            report += f'    <failure message="{test["message"]}">{test["traceback"]}</failure>\n'

+        elif test["status"] == "error":

+            report += f'    <error message="{test["message"]}">{test["traceback"]}</error>\n'

+        report += '  </testcase>\n'

+    

+    report += '</testsuite>'

+    

+    return report

 

 

 def _format_lines(lines):


--- a/decoupled/60/0.8_0.2/174/pytest-dev_pytest/src/_pytest/assertion/util.py
+++ b/decoupled/60/0.8_0.2/174/pytest-dev_pytest/src/_pytest/assertion/util.py
@@ -50,39 +50,50 @@
     return lines

 

 

-def _format_lines(lines):

-    """Format the individual lines

-

-    This will replace the '{', '}' and '~' characters of our mini

-    formatting language with the proper 'where ...', 'and ...' and ' +

-    ...' text, taking care of indentation along the way.

-

-    Return a list of formatted lines.

-    """

-    result = lines[:1]

-    stack = [0]

-    stackcnt = [0]

-    for line in lines[1:]:

-        if line.startswith("{"):

-            if stackcnt[-1]:

-                s = "and   "

-            else:

-                s = "where "

-            stack.append(len(result))

-            stackcnt[-1] += 1

-            stackcnt.append(0)

-            result.append(" +" + "  " * (len(stack) - 1) + s + line[1:])

-        elif line.startswith("}"):

-            stack.pop()

-            stackcnt.pop()

-            result[stack[-1]] += line[1:]

-        else:

-            assert line[0] in ["~", ">"]

-            stack[-1] += 1

-            indent = len(stack) if line.startswith("~") else len(stack) - 1

-            result.append("  " * indent + line[1:])

-    assert len(stack) == 1

-    return result

+import xml.etree.ElementTree as ET

+import platform

+import datetime

+

+def generate_junit_xml(test_results):

+    root = ET.Element("testsuite", name="check", tests=str(len(test_results)), errors="0", failures=str(len([result for result in test_results if result.outcome == 'failed'])), skipped="0", time="0.049")

+    

+    # Add hostname and timestamp properties

+    hostname = platform.node()

+    timestamp = datetime.datetime.now().isoformat()

+    root.set("hostname", hostname)

+    root.set("timestamp", timestamp)

+    

+    for result in test_results:

+        testcase = ET.SubElement(root, "testcase", classname=result.classname, name=result.name, file=result.file, line=str(result.line), time=str(result.time))

+        

+        if result.outcome == 'failed':

+            ET.SubElement(testcase, "failure", message=result.message, type=result.type).text = result.error_details

+        elif result.outcome == 'skipped':

+            ET.SubElement(testcase, "skipped", message=result.message, type=result.type).text = result.error_details

+    

+    return ET.tostring(root, encoding="utf-8", xml_declaration=True)

+

+# Example usage

+class TestResult:

+    def __init__(self, outcome, classname, name, file, line, time, message=None, type=None, error_details=None):

+        self.outcome = outcome

+        self.classname = classname

+        self.name = name

+        self.file = file

+        self.line = line

+        self.time = time

+        self.message = message

+        self.type = type

+        self.error_details = error_details

+

+test_results = [

+    TestResult('passed', 'test_sample.TestClass', 'test_addOne_normal', 'test_sample.py', 3, 0.001),

+    TestResult('passed', 'test_sample.TestClass', 'test_addOne_edge', 'test_sample.py', 6, 0.001),

+    TestResult('failed', 'test_sample.TestClass', 'test_addOne_error', 'test_sample.py', 9, 0.002, message="AssertionError", type="test", error_details="1 + 1 != 2")

+]

+

+xml_report = generate_junit_xml(test_results)

+print(xml_report.decode())

 

 

 def issequence(x):


--- a/decoupled/60/0.8_0.2/174/pytest-dev_pytest/testing/test_runner.py
+++ b/decoupled/60/0.8_0.2/174/pytest-dev_pytest/testing/test_runner.py
@@ -860,6 +860,29 @@
     result.stdout.fnmatch_lines(["*test_fix*", "*fixture*'missing'*not found*"])

 

 

+import pytest

+import sys

+import os

+from datetime import datetime

+

+def pytest_configure(config):

+    """Customize the JUnit XML report to include hostname and timestamp."""

+    # Add hostname to the JUnit XML report

+    config._metadata['hostname'] = os.uname().nodename

+

+    # Add timestamp to the JUnit XML report

+    config._metadata['timestamp'] = datetime.now().isoformat()

+

+def pytest_xml_report_header(config):

+    """Add hostname and timestamp to the JUnit XML report header."""

+    return "Hostname: {}, Timestamp: {}".format(config._metadata['hostname'], config._metadata['timestamp'])

+

+def pytest_runtest_logreport(report):

+    """Log the report to include hostname and timestamp in the JUnit XML report."""

+    if report.when == "call":

+        report.nodeid += " (Hostname: {}, Timestamp: {})".format(config._metadata['hostname'], config._metadata['timestamp'])

+

+# Example usage of the pytest configuration

 def test_store_except_info_on_error():

     """ Test that upon test failure, the exception info is stored on

     sys.last_traceback and friends.


