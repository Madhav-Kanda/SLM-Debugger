--- a/decoupled/60/0.8_0.2/193/scikit-learn_scikit-learn/sklearn/ensemble/tests/test_forest.py
+++ b/decoupled/60/0.8_0.2/193/scikit-learn_scikit-learn/sklearn/ensemble/tests/test_forest.py
@@ -1294,18 +1294,39 @@
                          [RandomForestClassifier, RandomForestRegressor,

                           ExtraTreesClassifier, ExtraTreesRegressor,

                           RandomTreesEmbedding])

-def test_nestimators_future_warning(forest):

+import numpy as np

+from sklearn.ensemble import IsolationForest

+from sklearn.utils.validation import check_random_state

+from sklearn.utils.testing import assert_no_warnings, assert_warns_message

+from sklearn.exceptions import FutureWarning

+

+def test_nestimators_future_warning(forest, warm_start=False):

     # FIXME: to be removed 0.22

 

     # When n_estimators default value is used

     msg_future = ("The default value of n_estimators will change from "

                   "10 in version 0.20 to 100 in 0.22.")

-    est = forest()

+    est = forest(n_estimators=100, warm_start=warm_start)

     est = assert_warns_message(FutureWarning, msg_future, est.fit, X, y)

 

     # When n_estimators is a valid value not equal to the default

-    est = forest(n_estimators=100)

+    est = forest(n_estimators=100, warm_start=warm_start)

     est = assert_no_warnings(est.fit, X, y)

+

+    # Test warm_start functionality

+    if warm_start:

+        # Fit the model for the first time

+        est.fit(X, y)

+        # Increment n_estimators and fit again

+        est.n_estimators += 100

+        est.fit(X, y)

+        # Check that the number of trees has increased

+        assert len(est.estimators_) > 100

+

+# Example usage

+X = np.random.randn(100, 2)

+y = np.random.randint(0, 2, 100)

+test_nestimators_future_warning(IsolationForest, warm_start=True)

 

 

 class MyBackend(DEFAULT_JOBLIB_BACKEND):
