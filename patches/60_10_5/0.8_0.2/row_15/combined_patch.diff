--- a/decoupled/60/0.8_0.2/15/django_django/django/db/models/fields/related_descriptors.py
+++ b/decoupled/60/0.8_0.2/15/django_django/django/db/models/fields/related_descriptors.py
@@ -191,71 +191,71 @@
         else:

             return rel_obj

 

-    def __set__(self, instance, value):

-        """

-        Set the related instance through the forward relation.

-

-        With the example above, when setting ``child.parent = parent``:

-

-        - ``self`` is the descriptor managing the ``parent`` attribute

-        - ``instance`` is the ``child`` instance

-        - ``value`` is the ``parent`` instance on the right of the equal sign

-        """

-        # An object must be an instance of the related class.

-        if value is not None and not isinstance(value, self.field.remote_field.model._meta.concrete_model):

-            raise ValueError(

-                'Cannot assign "%r": "%s.%s" must be a "%s" instance.' % (

-                    value,

-                    instance._meta.object_name,

-                    self.field.name,

-                    self.field.remote_field.model._meta.object_name,

-                )

+def __set__(self, instance, value):

+    """

+    Set the related instance through the forward relation.

+

+    With the example above, when setting ``child.parent = parent``:

+

+    - ``self`` is the descriptor managing the ``parent`` attribute

+    - ``instance`` is the ``child`` instance

+    - ``value`` is the ``parent`` instance on the right of the equal sign

+    """

+    # An object must be an instance of the related class.

+    if value is not None and not isinstance(value, self.field.remote_field.model._meta.concrete_model):

+        raise ValueError(

+            'Cannot assign "%r": "%s.%s" must be a "%s" instance.' % (

+                value,

+                instance._meta.object_name,

+                self.field.name,

+                self.field.remote_field.model._meta.object_name,

             )

-        elif value is not None:

-            if instance._state.db is None:

-                instance._state.db = router.db_for_write(instance.__class__, instance=value)

-            if value._state.db is None:

-                value._state.db = router.db_for_write(value.__class__, instance=instance)

-            if not router.allow_relation(value, instance):

-                raise ValueError('Cannot assign "%r": the current database router prevents this relation.' % value)

-

-        remote_field = self.field.remote_field

-        # If we're setting the value of a OneToOneField to None, we need to clear

-        # out the cache on any old related object. Otherwise, deleting the

-        # previously-related object will also cause this object to be deleted,

-        # which is wrong.

-        if value is None:

-            # Look up the previously-related object, which may still be available

-            # since we've not yet cleared out the related field.

-            # Use the cache directly, instead of the accessor; if we haven't

-            # populated the cache, then we don't care - we're only accessing

-            # the object to invalidate the accessor cache, so there's no

-            # need to populate the cache just to expire it again.

-            related = self.field.get_cached_value(instance, default=None)

-

-            # If we've got an old related object, we need to clear out its

-            # cache. This cache also might not exist if the related object

-            # hasn't been accessed yet.

-            if related is not None:

-                remote_field.set_cached_value(related, None)

-

-            for lh_field, rh_field in self.field.related_fields:

-                setattr(instance, lh_field.attname, None)

-

-        # Set the values of the related field.

-        else:

-            for lh_field, rh_field in self.field.related_fields:

-                setattr(instance, lh_field.attname, getattr(value, rh_field.attname))

-

-        # Set the related instance cache used by __get__ to avoid an SQL query

-        # when accessing the attribute we just set.

-        self.field.set_cached_value(instance, value)

-

-        # If this is a one-to-one relation, set the reverse accessor cache on

-        # the related object to the current instance to avoid an extra SQL

-        # query if it's accessed later on.

-        if value is not None and not remote_field.multiple:

-            remote_field.set_cached_value(value, instance)

+        )

+    elif value is not None:

+        if instance._state.db is None:

+            instance._state.db = router.db_for_write(instance.__class__, instance=value)

+        if value._state.db is None:

+            value._state.db = router.db_for_write(value.__class__, instance=instance)

+        if not router.allow_relation(value, instance):

+            raise ValueError('Cannot assign "%r": the current database router prevents this relation.' % value)

+

+    remote_field = self.field.remote_field

+    # If we're setting the value of a OneToOneField to None, we need to clear

+    # out the cache on any old related object. Otherwise, deleting the

+    # previously-related object will also cause this object to be deleted,

+    # which is wrong.

+    if value is None:

+        # Look up the previously-related object, which may still be available

+        # since we've not yet cleared out the related field.

+        # Use the cache directly, instead of the accessor; if we haven't

+        # populated the cache, then we don't care - we're only accessing

+        # the object to invalidate the accessor cache, so there's no

+        # need to populate the cache just to expire it again.

+        related = self.field.get_cached_value(instance, default=None)

+

+        # If we've got an old related object, we need to clear out its

+        # cache. This cache also might not exist if the related object

+        # hasn't been accessed yet.

+        if related is not None:

+            remote_field.set_cached_value(related, None)

+

+        for lh_field, rh_field in self.field.related_fields:

+            setattr(instance, lh_field.attname, None)

+

+    # Set the values of the related field.

+    else:

+        for lh_field, rh_field in self.field.related_fields:

+            setattr(instance, lh_field.attname, getattr(value, rh_field.attname))

+

+    # Set the related instance cache used by __get__ to avoid an SQL query

+    # when accessing the attribute we just set.

+    self.field.set_cached_value(instance, value)

+

+    # If this is a one-to-one relation, set the reverse accessor cache on

+    # the related object to the current instance to avoid an extra SQL

+    # query if it's accessed later on.

+    if value is not None and not remote_field.multiple:

+        remote_field.set_cached_value(value, instance)

 

     def __reduce__(self):

         """


--- a/decoupled/60/0.8_0.2/15/django_django/django/db/models/sql/query.py
+++ b/decoupled/60/0.8_0.2/15/django_django/django/db/models/sql/query.py
@@ -537,106 +537,75 @@
         compiler = q.get_compiler(using=using)

         return '\n'.join(compiler.explain_query())

 

-    def combine(self, rhs, connector):

-        """

-        Merge the 'rhs' query into the current one (with any 'rhs' effects

-        being applied *after* (that is, "to the right of") anything in the

-        current query. 'rhs' is not modified during a call to this function.

-

-        The 'connector' parameter describes how to connect filters from the

-        'rhs' query.

-        """

-        assert self.model == rhs.model, \

-            "Cannot combine queries on two different base models."

-        assert self.can_filter(), \

-            "Cannot combine queries once a slice has been taken."

-        assert self.distinct == rhs.distinct, \

-            "Cannot combine a unique query with a non-unique query."

-        assert self.distinct_fields == rhs.distinct_fields, \

-            "Cannot combine queries with different distinct fields."

-

-        # Work out how to relabel the rhs aliases, if necessary.

-        change_map = {}

-        conjunction = (connector == AND)

-

-        # Determine which existing joins can be reused. When combining the

-        # query with AND we must recreate all joins for m2m filters. When

-        # combining with OR we can reuse joins. The reason is that in AND

-        # case a single row can't fulfill a condition like:

-        #     revrel__col=1 & revrel__col=2

-        # But, there might be two different related rows matching this

-        # condition. In OR case a single True is enough, so single row is

-        # enough, too.

-        #

-        # Note that we will be creating duplicate joins for non-m2m joins in

-        # the AND case. The results will be correct but this creates too many

-        # joins. This is something that could be fixed later on.

-        reuse = set() if conjunction else set(self.alias_map)

-        # Base table must be present in the query - this is the same

-        # table on both sides.

-        self.get_initial_alias()

-        joinpromoter = JoinPromoter(connector, 2, False)

-        joinpromoter.add_votes(

-            j for j in self.alias_map if self.alias_map[j].join_type == INNER)

-        rhs_votes = set()

-        # Now, add the joins from rhs query into the new query (skipping base

-        # table).

-        rhs_tables = list(rhs.alias_map)[1:]

-        for alias in rhs_tables:

-            join = rhs.alias_map[alias]

-            # If the left side of the join was already relabeled, use the

-            # updated alias.

-            join = join.relabeled_clone(change_map)

-            new_alias = self.join(join, reuse=reuse)

-            if join.join_type == INNER:

-                rhs_votes.add(new_alias)

-            # We can't reuse the same join again in the query. If we have two

-            # distinct joins for the same connection in rhs query, then the

-            # combined query must have two joins, too.

-            reuse.discard(new_alias)

-            if alias != new_alias:

-                change_map[alias] = new_alias

-            if not rhs.alias_refcount[alias]:

-                # The alias was unused in the rhs query. Unref it so that it

-                # will be unused in the new query, too. We have to add and

-                # unref the alias so that join promotion has information of

-                # the join type for the unused alias.

-                self.unref_alias(new_alias)

-        joinpromoter.add_votes(rhs_votes)

-        joinpromoter.update_join_types(self)

-

-        # Now relabel a copy of the rhs where-clause and add it to the current

-        # one.

-        w = rhs.where.clone()

-        w.relabel_aliases(change_map)

-        self.where.add(w, connector)

-

-        # Selection columns and extra extensions are those provided by 'rhs'.

-        if rhs.select:

-            self.set_select([col.relabeled_clone(change_map) for col in rhs.select])

-        else:

-            self.select = ()

-

-        if connector == OR:

-            # It would be nice to be able to handle this, but the queries don't

-            # really make sense (or return consistent value sets). Not worth

-            # the extra complexity when you can write a real query instead.

-            if self.extra and rhs.extra:

-                raise ValueError("When merging querysets using 'or', you cannot have extra(select=...) on both sides.")

-        self.extra.update(rhs.extra)

-        extra_select_mask = set()

-        if self.extra_select_mask is not None:

-            extra_select_mask.update(self.extra_select_mask)

-        if rhs.extra_select_mask is not None:

-            extra_select_mask.update(rhs.extra_select_mask)

-        if extra_select_mask:

-            self.set_extra_mask(extra_select_mask)

-        self.extra_tables += rhs.extra_tables

-

-        # Ordering uses the 'rhs' ordering, unless it has none, in which case

-        # the current ordering is used.

-        self.order_by = rhs.order_by or self.order_by

-        self.extra_order_by = rhs.extra_order_by or self.extra_order_by

+def combine(self, rhs, connector):

+    """

+    Merge the 'rhs' query into the current one (with any 'rhs' effects

+    being applied *after* (that is, "to the right of") anything in the

+    current query. 'rhs' is not modified during a call to this function.

+

+    The 'connector' parameter describes how to connect filters from the

+    'rhs' query.

+    """

+    assert self.model == rhs.model, \

+        "Cannot combine queries on two different base models."

+    assert self.can_filter(), \

+        "Cannot combine queries once a slice has been taken."

+    assert self.distinct == rhs.distinct, \

+        "Cannot combine a unique query with a non-unique query."

+    assert self.distinct_fields == rhs.distinct_fields, \

+        "Cannot combine queries with different distinct fields."

+

+    # Work out how to relabel the rhs aliases, if necessary.

+    change_map = {}

+    conjunction = (connector == AND)

+

+    # Determine which existing joins can be reused. When combining the

+    # query with AND we must recreate all joins for m2m filters. When

+    # combining with OR we can reuse joins. The reason is that in AND

+    # case a single row can't fulfill a condition like:

+    #     revrel__col=1 & revrel__col=2

+    # But, there might be two different related rows matching this

+    # condition. In OR case a single True is enough, so single row is

+    # enough, too.

+    #

+    # Note that we will be creating duplicate joins for non-m2m joins in

+    # the AND case. The results will be correct but this creates too many

+    # joins. This is something that could be fixed later on.

+    reuse = set() if conjunction else set(self.alias_map)

+    # Base table must be present in the query - this is the same

+    # table on both sides.

+    self.get_initial_alias()

+    joinpromoter = JoinPromoter(connector, 2, False)

+    joinpromoter.add_votes(

+        j for j in self.alias_map if self.alias_map[j].join_type == INNER)

+    rhs_votes = set()

+    # Now, add the joins from rhs query into the new query (skipping base

+    # table).

+    rhs_tables = list(rhs.alias_map)[1:]

+    for alias in rhs_tables:

+        join = rhs.alias_map[alias]

+        # If the left side of the join was already relabeled, use the

+        # updated alias.

+        join = join.relabeled_clone(change_map)

+        new_alias = self.join(join, reuse=reuse)

+        if join.join_type == INNER:

+            rhs_votes.add(new_alias)

+        # We can't reuse the same join again in the query. If we have two

+        # distinct joins for the same connection in rhs query, then the

+        # combined query must have two joins, too.

+        reuse.discard(new_alias)

+        if alias != new_alias:

+            change_map[alias] = new_alias

+        if not rhs.alias_refcount[alias]:

+            # The alias was unused in the rhs query. Unref it so that it

+            # will be unused in the new query, too. We have to add and

+            # unref the alias so that join promotion has information of

+            # the join type for the unused alias.

+            self.unref_alias(new_alias)

+    joinpromoter.add_votes(rhs_votes)

+    joinpromoter.update_join_types(self)

+

+    # Now relabel a copy of the rhs where-clause and add it to the

 

     def deferred_to_data(self, target, callback):

         """


--- a/decoupled/60/0.8_0.2/15/django_django/django/db/models/query_utils.py
+++ b/decoupled/60/0.8_0.2/15/django_django/django/db/models/query_utils.py
@@ -280,6 +280,7 @@
             opts.concrete_model in model._meta.get_parent_list() or

             model in opts.get_parent_list()

         )

+    

     # If the field is a primary key, then doing a query against the field's

     # model is ok, too. Consider the case:

     # class Restaurant(models.Model):

@@ -289,9 +290,12 @@
     # give Place's opts as the target opts, but Restaurant isn't compatible

     # with that. This logic applies only to primary keys, as when doing __in=qs,

     # we are going to turn this into __in=qs.values('pk') later on.

+    # Additionally, for proxy models, we need to ensure that the proxy model

+    # is treated as the concrete model for permission checks.

     return (

         check(target_opts) or

-        (getattr(field, 'primary_key', False) and check(field.model._meta))

+        (getattr(field, 'primary_key', False) and check(field.model._meta)) or

+        (model._meta.is_proxy and model._meta.concrete_model == target_opts.concrete_model)

     )

 

 


--- a/decoupled/60/0.8_0.2/15/django_django/django/db/models/fields/related_descriptors.py
+++ b/decoupled/60/0.8_0.2/15/django_django/django/db/models/fields/related_descriptors.py
@@ -144,52 +144,52 @@
         # Assuming the database enforces foreign keys, this won't fail.

         return qs.get(self.field.get_reverse_related_filter(instance))

 

-    def __get__(self, instance, cls=None):

-        """

-        Get the related instance through the forward relation.

-

-        With the example above, when getting ``child.parent``:

-

-        - ``self`` is the descriptor managing the ``parent`` attribute

-        - ``instance`` is the ``child`` instance

-        - ``cls`` is the ``Child`` class (we don't need it)

-        """

-        if instance is None:

-            return self

-

-        # The related instance is loaded from the database and then cached

-        # by the field on the model instance state. It can also be pre-cached

-        # by the reverse accessor (ReverseOneToOneDescriptor).

-        try:

-            rel_obj = self.field.get_cached_value(instance)

-        except KeyError:

-            has_value = None not in self.field.get_local_related_value(instance)

-            ancestor_link = instance._meta.get_ancestor_link(self.field.model) if has_value else None

-            if ancestor_link and ancestor_link.is_cached(instance):

-                # An ancestor link will exist if this field is defined on a

-                # multi-table inheritance parent of the instance's class.

-                ancestor = ancestor_link.get_cached_value(instance)

-                # The value might be cached on an ancestor if the instance

-                # originated from walking down the inheritance chain.

-                rel_obj = self.field.get_cached_value(ancestor, default=None)

-            else:

-                rel_obj = None

-            if rel_obj is None and has_value:

-                rel_obj = self.get_object(instance)

-                remote_field = self.field.remote_field

-                # If this is a one-to-one relation, set the reverse accessor

-                # cache on the related object to the current instance to avoid

-                # an extra SQL query if it's accessed later on.

-                if not remote_field.multiple:

-                    remote_field.set_cached_value(rel_obj, instance)

-            self.field.set_cached_value(instance, rel_obj)

-

-        if rel_obj is None and not self.field.null:

-            raise self.RelatedObjectDoesNotExist(

-                "%s has no %s." % (self.field.model.__name__, self.field.name)

-            )

+def __get__(self, instance, cls=None):

+    """

+    Get the related instance through the forward relation.

+

+    With the example above, when getting ``child.parent``:

+

+    - ``self`` is the descriptor managing the ``parent`` attribute

+    - ``instance`` is the ``child`` instance

+    - ``cls`` is the ``Child`` class (we don't need it)

+    """

+    if instance is None:

+        return self

+

+    # The related instance is loaded from the database and then cached

+    # by the field on the model instance state. It can also be pre-cached

+    # by the reverse accessor (ReverseOneToOneDescriptor).

+    try:

+        rel_obj = self.field.get_cached_value(instance)

+    except KeyError:

+        has_value = None not in self.field.get_local_related_value(instance)

+        ancestor_link = instance._meta.get_ancestor_link(self.field.model) if has_value else None

+        if ancestor_link and ancestor_link.is_cached(instance):

+            # An ancestor link will exist if this field is defined on a

+            # multi-table inheritance parent of the instance's class.

+            ancestor = ancestor_link.get_cached_value(instance)

+            # The value might be cached on an ancestor if the instance

+            # originated from walking down the inheritance chain.

+            rel_obj = self.field.get_cached_value(ancestor, default=None)

         else:

-            return rel_obj

+            rel_obj = None

+        if rel_obj is None and has_value:

+            rel_obj = self.get_object(instance)

+            remote_field = self.field.remote_field

+            # If this is a one-to-one relation, set the reverse accessor

+            # cache on the related object to the current instance to avoid

+            # an extra SQL query if it's accessed later on.

+            if not remote_field.multiple:

+                remote_field.set_cached_value(rel_obj, instance)

+        self.field.set_cached_value(instance, rel_obj)

+

+    if rel_obj is None and not self.field.null:

+        raise self.RelatedObjectDoesNotExist(

+            "%s has no %s." % (self.field.model.__name__, self.field.name)

+        )

+    else:

+        return rel_obj

 

     def __set__(self, instance, value):

         """


--- a/decoupled/60/0.8_0.2/15/django_django/django/db/models/sql/query.py
+++ b/decoupled/60/0.8_0.2/15/django_django/django/db/models/sql/query.py
@@ -2245,58 +2245,52 @@
         """

         self.votes.update(votes)

 

-    def update_join_types(self, query):

-        """

-        Change join types so that the generated query is as efficient as

-        possible, but still correct. So, change as many joins as possible

-        to INNER, but don't make OUTER joins INNER if that could remove

-        results from the query.

-        """

-        to_promote = set()

-        to_demote = set()

-        # The effective_connector is used so that NOT (a AND b) is treated

-        # similarly to (a OR b) for join promotion.

-        for table, votes in self.votes.items():

-            # We must use outer joins in OR case when the join isn't contained

-            # in all of the joins. Otherwise the INNER JOIN itself could remove

-            # valid results. Consider the case where a model with rel_a and

-            # rel_b relations is queried with rel_a__col=1 | rel_b__col=2. Now,

-            # if rel_a join doesn't produce any results is null (for example

-            # reverse foreign key or null value in direct foreign key), and

-            # there is a matching row in rel_b with col=2, then an INNER join

-            # to rel_a would remove a valid match from the query. So, we need

-            # to promote any existing INNER to LOUTER (it is possible this

-            # promotion in turn will be demoted later on).

-            if self.effective_connector == 'OR' and votes < self.num_children:

-                to_promote.add(table)

-            # If connector is AND and there is a filter that can match only

-            # when there is a joinable row, then use INNER. For example, in

-            # rel_a__col=1 & rel_b__col=2, if either of the rels produce NULL

-            # as join output, then the col=1 or col=2 can't match (as

-            # NULL=anything is always false).

-            # For the OR case, if all children voted for a join to be inner,

-            # then we can use INNER for the join. For example:

-            #     (rel_a__col__icontains=Alex | rel_a__col__icontains=Russell)

-            # then if rel_a doesn't produce any rows, the whole condition

-            # can't match. Hence we can safely use INNER join.

-            if self.effective_connector == 'AND' or (

-                    self.effective_connector == 'OR' and votes == self.num_children):

-                to_demote.add(table)

-            # Finally, what happens in cases where we have:

-            #    (rel_a__col=1|rel_b__col=2) & rel_a__col__gte=0

-            # Now, we first generate the OR clause, and promote joins for it

-            # in the first if branch above. Both rel_a and rel_b are promoted

-            # to LOUTER joins. After that we do the AND case. The OR case

-            # voted no inner joins but the rel_a__col__gte=0 votes inner join

-            # for rel_a. We demote it back to INNER join (in AND case a single

-            # vote is enough). The demotion is OK, if rel_a doesn't produce

-            # rows, then the rel_a__col__gte=0 clause can't be true, and thus

-            # the whole clause must be false. So, it is safe to use INNER

-            # join.

-            # Note that in this example we could just as well have the __gte

-            # clause and the OR clause swapped. Or we could replace the __gte

-            # clause with an OR clause containing rel_a__col=1|rel_a__col=2,

-            # and again we could safely demote to INNER.

-        query.promote_joins(to_promote)

-        query.demote_joins(to_demote)

-        return to_demote

+from django.db import migrations, models

+from django.contrib.auth.models import Permission

+from django.contrib.contenttypes.models import ContentType

+

+def update_proxy_permissions(apps, schema_editor):

+    ContentType = apps.get_model('contenttypes', 'ContentType')

+    Permission = apps.get_model('auth', 'Permission')

+

+    # Get all proxy models

+    proxy_models = [model for model in apps.get_models() if model._meta.proxy]

+

+    for model in proxy_models:

+        # Get the original model

+        original_model = model._meta.proxy_for_model

+

+        # Get the content type for the original model

+        original_content_type = ContentType.objects.get_for_model(original_model)

+

+        # Get all permissions for the original model

+        original_permissions = Permission.objects.filter(content_type=original_content_type)

+

+        # Get the content type for the proxy model

+        proxy_content_type = ContentType.objects.get_for_model(model)

+

+        # Update or remove permissions for the proxy model

+        for permission in original_permissions:

+            # Check if the permission already exists for the proxy model

+            if Permission.objects.filter(content_type=proxy_content_type, codename=permission.codename).exists():

+                # If it exists, update the content type

+                permission.content_type = proxy_content_type

+                permission.save()

+            else:

+                # If it doesn't exist, create a new permission

+                Permission.objects.create(

+                    name=permission.name,

+                    codename=permission.codename,

+                    content_type=proxy_content_type,

+                    model=model.__name__.lower()

+                )

+

+class Migration(migrations.Migration):

+

+    dependencies = [

+        ('yourappname', '0010_previous_migration'),

+    ]

+

+    operations = [

+        migrations.RunPython(update_proxy_permissions),

+    ]


