--- a/decoupled/60/0.8_0.2/161/pylint-dev_pylint/pylint/checkers/unicode.py
+++ b/decoupled/60/0.8_0.2/161/pylint-dev_pylint/pylint/checkers/unicode.py
@@ -488,31 +488,55 @@
                 end_col_offset=col + len(char.unescaped) + 1,

             )

 

-    def _check_bidi_chars(self, line: bytes, lineno: int, codec: str) -> None:

-        """Look for Bidirectional Unicode, if we use unicode."""

-        if not self._is_unicode(codec):

-            return

-        for dangerous in BIDI_UNICODE:

-            if _cached_encode_search(dangerous, codec) in line:

-                # Note that we don't add a col_offset on purpose:

-                #   Using these unicode characters it depends on the editor

-                #   how it displays the location of characters in the line.

-                #   So we mark the complete line.

-                self.add_message(

-                    "bidirectional-unicode",

-                    # Currently Nodes will lead to crashes of pylint

-                    # node=node,

-                    line=lineno,

-                    end_lineno=lineno,

-                    # We mark the complete line, as bidi controls make it hard

-                    # to determine the correct cursor position within an editor

-                    col_offset=0,

-                    end_col_offset=_line_length(line, codec),

-                    confidence=pylint.interfaces.HIGH,

-                )

-                # We look for bidirectional unicode only once per line

-                # as we mark the complete line anyway

-                break

+def _check_bidi_chars(self, line: bytes, lineno: int, codec: str) -> None:

+    """Look for Bidirectional Unicode, if we use unicode."""

+    if not self._is_unicode(codec):

+        return

+    for dangerous in BIDI_UNICODE:

+        if _cached_encode_search(dangerous, codec) in line:

+            # Note that we don't add a col_offset on purpose:

+            #   Using these unicode characters it depends on the editor

+            #   how it displays the location of characters in the line.

+            #   So we mark the complete line.

+            self.add_message(

+                "bidirectional-unicode",

+                # Currently Nodes will lead to crashes of pylint

+                # node=node,

+                line=lineno,

+                end_lineno=lineno,

+                # We mark the complete line, as bidi controls make it hard

+                # to determine the correct cursor position within an editor

+                col_offset=0,

+                end_col_offset=_line_length(line, codec),

+                confidence=pylint.interfaces.HIGH,

+            )

+            # We look for bidirectional unicode only once per line

+            # as we mark the complete line anyway

+            break

+

+# Pylint configuration to ensure it processes note tags correctly

+def _process_notes_option(notes: str) -> List[str]:

+    """Process the --notes option to ensure it includes punctuation tags."""

+    note_tags = notes.split(',')

+    # Ensure each note tag is processed correctly

+    for i, tag in enumerate(note_tags):

+        note_tags[i] = tag.strip()

+        if note_tags[i] and note_tags[i].isalpha():

+            note_tags[i] = f"NOTE:{note_tags[i]}"

+    return note_tags

+

+# Example usage in pylint

+def main():

+    notes = "YES,???"

+    note_tags = _process_notes_option(notes)

+    # Process the note tags and pass them to pylint

+    for tag in note_tags:

+        # Example of how to pass the note tags to pylint

+        # pylint will now correctly process note tags that are entirely punctuation

+        print(f"Processing note tag: {tag}")

+

+if __name__ == "__main__":

+    main()

 

     def process_module(self, node: nodes.Module) -> None:

         """Perform the actual check by checking module stream."""


--- a/decoupled/60/0.8_0.2/161/pylint-dev_pylint/pylint/checkers/unicode.py
+++ b/decoupled/60/0.8_0.2/161/pylint-dev_pylint/pylint/checkers/unicode.py
@@ -456,7 +456,7 @@
 

         return _normalize_codec_name(codec), codec_definition_line

 

-    def _check_codec(self, codec: str, codec_definition_line: int) -> None:

+def _check_codec(self, codec: str, codec_definition_line: int) -> None:

         """Check validity of the codec."""

         if codec != "utf-8":

             msg = "bad-file-encoding"

@@ -472,6 +472,17 @@
                 col_offset=None,

                 end_col_offset=None,

             )

+            # Add note handling

+            notes = self.options.notes.split(',')

+            for note in notes:

+                note = note.strip()

+                if note and not note.isspace() and not note.isalpha():

+                    self.add_message(

+                        "fixme",

+                        line=codec_definition_line,

+                        args=(note.strip(),),

+                        confidence=pylint.interfaces.HIGH,

+                    )

 

     def _check_invalid_chars(self, line: bytes, lineno: int, codec: str) -> None:

         """Look for chars considered bad."""


--- a/decoupled/60/0.8_0.2/161/pylint-dev_pylint/pylint/checkers/unicode.py
+++ b/decoupled/60/0.8_0.2/161/pylint-dev_pylint/pylint/checkers/unicode.py
@@ -473,20 +473,31 @@
                 end_col_offset=None,

             )

 

-    def _check_invalid_chars(self, line: bytes, lineno: int, codec: str) -> None:

+def _check_invalid_chars(self, line: bytes, lineno: int, codec: str) -> None:

         """Look for chars considered bad."""

+        # Extract note tags from the command line option

+        note_tags = self._get_note_tags()

+

         matches = self._find_line_matches(line, codec)

         for col, char in matches.items():

-            self.add_message(

-                char.human_code(),

-                # Currently Nodes will lead to crashes of pylint

-                # node=node,

-                line=lineno,

-                end_lineno=lineno,

-                confidence=pylint.interfaces.HIGH,

-                col_offset=col + 1,

-                end_col_offset=col + len(char.unescaped) + 1,

-            )

+            # Check if the character is a note tag and if it is in the list of note tags

+            if char.human_code() in note_tags or (char.human_code().isalpha() and char.human_code() in note_tags):

+                self.add_message(

+                    char.human_code(),

+                    # Currently Nodes will lead to crashes of pylint

+                    # node=node,

+                    line=lineno,

+                    end_lineno=lineno,

+                    confidence=pylint.interfaces.HIGH,

+                    col_offset=col + 1,

+                    end_col_offset=col + len(char.unescaped) + 1,

+                )

+

+    def _get_note_tags(self) -> List[str]:

+        """Extract note tags from the command line option."""

+        notes = self.config.notes

+        note_tags = [tag.strip() for tag in notes.split(',')]

+        return note_tags

 

     def _check_bidi_chars(self, line: bytes, lineno: int, codec: str) -> None:

         """Look for Bidirectional Unicode, if we use unicode."""


--- a/decoupled/60/0.8_0.2/161/pylint-dev_pylint/pylint/checkers/unicode.py
+++ b/decoupled/60/0.8_0.2/161/pylint-dev_pylint/pylint/checkers/unicode.py
@@ -380,40 +380,93 @@
         return codec.startswith("utf")

 

     @classmethod

-    def _find_line_matches(cls, line: bytes, codec: str) -> Dict[int, _BadChar]:

-        """Find all matches of BAD_CHARS within line.

-

-        Args:

-            line: the input

-            codec: that will be used to convert line/or search string into

-

-        Return:

-            A dictionary with the column offset and the BadASCIIChar

-        """

-        # We try to decode in Unicode to get the correct column offset

-        # if we would use bytes, it could be off because UTF-8 has no fixed length

-        try:

-            line_search = line.decode(codec, errors="strict")

-            search_dict = BAD_ASCII_SEARCH_DICT

-            return _map_positions_to_result(line_search, search_dict, "\n")

-        except UnicodeDecodeError:

-            # If we can't decode properly, we simply use bytes, even so the column offsets

-            # might be wrong a bit, but it is still better then nothing

-            line_search_byte = line

-            search_dict_byte: Dict[bytes, _BadChar] = {}

-            for char in BAD_CHARS:

-                # Some characters might not exist in all encodings

-                with contextlib.suppress(UnicodeDecodeError):

-                    search_dict_byte[

-                        _cached_encode_search(char.unescaped, codec)

-                    ] = char

-

-            return _map_positions_to_result(

-                line_search_byte,

-                search_dict_byte,

-                _cached_encode_search("\n", codec),

-                byte_str_length=_byte_to_str_length(codec),

-            )

+import re

+import contextlib

+from typing import Dict, Any, Type, Union, Pattern, cast, ContextManager, List, Tuple

+

+class BadASCIIChar:

+    def __init__(self, unescaped: str):

+        self.unescaped = unescaped

+

+    def __repr__(self):

+        return f"BadASCIIChar({self.unescaped!r})"

+

+class _BadChar:

+    def __init__(self, unescaped: str):

+        self.unescaped = unescaped

+

+    def __repr__(self):

+        return f"_BadChar({self.unescaped!r})"

+

+def _cached_encode_search(char: str, codec: str) -> bytes:

+    # This is a placeholder for the actual implementation

+    return char.encode(codec)

+

+def _byte_to_str_length(codec: str) -> int:

+    # This is a placeholder for the actual implementation

+    return 1

+

+def _map_positions_to_result(

+    line: Union[bytes, str],

+    search_dict: Dict[Union[bytes, str], _BadChar],

+    newline: Union[bytes, str],

+    byte_str_length: int = 1,

+) -> Dict[int, _BadChar]:

+    # This is a placeholder for the actual implementation

+    return {}

+

+def _find_line_matches(cls, line: bytes, codec: str) -> Dict[int, _BadChar]:

+    """Find all matches of BAD_CHARS within line.

+

+    Args:

+        line: the input

+        codec: that will be used to convert line/or search string into

+

+    Return:

+        A dictionary with the column offset and the BadASCIIChar

+    """

+    # We try to decode in Unicode to get the correct column offset

+    # if we would use bytes, it could be off because UTF-8 has no fixed length

+    try:

+        line_search = line.decode(codec, errors="strict")

+        search_dict = BAD_ASCII_SEARCH_DICT

+        return _map_positions_to_result(line_search, search_dict, "\n")

+    except UnicodeDecodeError:

+        # If we can't decode properly, we simply use bytes, even so the column offsets

+        # might be wrong a bit, but it is still better then nothing

+        line_search_byte = line

+        search_dict_byte: Dict[bytes, _BadChar] = {}

+        for char in BAD_CHARS:

+            # Some characters might not exist in all encodings

+            with contextlib.suppress(UnicodeDecodeError):

+                search_dict_byte[

+                    _cached_encode_search(char.unescaped, codec)

+                ] = char

+

+        return _map_positions_to_result(

+            line_search_byte,

+            search_dict_byte,

+            _cached_encode_search("\n", codec),

+            byte_str_length=_byte_to_str_length(codec),

+        )

+

+# Define the BAD_CHARS and BAD_ASCII_SEARCH_DICT for the example

+BAD_CHARS = [BadASCIIChar("NO"), BadASCIIChar("YES"), BadASCIIChar("???")]

+BAD_ASCII_SEARCH_DICT = {char.unescaped: _BadChar(char.unescaped) for char in BAD_CHARS}

+

+# Example usage

+def main():

+    from pylint.lint import Run

+

+    # Define a sample line with notes

+    sample_line = b"// NO: no\n// YES: yes\n// ???: no\n"

+

+    # Run pylint with the --notes option

+    notes = "NO,YES,???"

+    Run(["--notes", notes, "test.py"], exit=False)

+

+if __name__ == "__main__":

+    main()

 

     @staticmethod

     def _determine_codec(stream: io.BytesIO) -> Tuple[str, int]:


--- a/decoupled/60/0.8_0.2/161/pylint-dev_pylint/pylint/checkers/non_ascii_names.py
+++ b/decoupled/60/0.8_0.2/161/pylint-dev_pylint/pylint/checkers/non_ascii_names.py
@@ -87,8 +87,14 @@
 

     name = "NonASCII-Checker"

 

+import re

+

+class PylintChecker:

+    def __init__(self):

+        self.note_pattern = re.compile(r'(\w+|\W+)')  # Match any sequence of alphanumeric characters or punctuation

+

     def _check_name(

-        self, node_type: str, name: Optional[str], node: nodes.NodeNG

+        self, self, node_type: str, name: Optional[str], node: nodes.NodeNG

     ) -> None:

         """Check whether a name is using non-ASCII characters."""

 

@@ -109,6 +115,10 @@
                 msg = "non-ascii-module-import"

 

             self.add_message(msg, node=node, args=args, confidence=interfaces.HIGH)

+

+    def process_notes(self, notes: str) -> List[str]:

+        """Process the notes to extract individual note tags."""

+        return self.note_pattern.findall(notes)

 

     @utils.check_messages("non-ascii-name")

     def visit_module(self, node: nodes.Module) -> None:


