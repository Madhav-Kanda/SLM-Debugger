--- a/decoupled/60/0.8_0.2/189/scikit-learn_scikit-learn/sklearn/decomposition/dict_learning.py
+++ b/decoupled/60/0.8_0.2/189/scikit-learn_scikit-learn/sklearn/decomposition/dict_learning.py
@@ -123,61 +123,7 @@
             lasso_lars.fit(dictionary.T, X.T, Xy=cov)

             new_code = lasso_lars.coef_

         finally:

-            np.seterr(**err_mgt)

-

-    elif algorithm == 'lasso_cd':

-        alpha = float(regularization) / n_features  # account for scaling

-

-        # TODO: Make verbosity argument for Lasso?

-        # sklearn.linear_model.coordinate_descent.enet_path has a verbosity

-        # argument that we could pass in from Lasso.

-        clf = Lasso(alpha=alpha, fit_intercept=False, normalize=False,

-                    precompute=gram, max_iter=max_iter, warm_start=True,

-                    positive=positive)

-

-        if init is not None:

-            clf.coef_ = init

-

-        clf.fit(dictionary.T, X.T, check_input=check_input)

-        new_code = clf.coef_

-

-    elif algorithm == 'lars':

-        try:

-            err_mgt = np.seterr(all='ignore')

-

-            # Not passing in verbose=max(0, verbose-1) because Lars.fit already

-            # corrects the verbosity level.

-            lars = Lars(fit_intercept=False, verbose=verbose, normalize=False,

-                        precompute=gram, n_nonzero_coefs=int(regularization),

-                        fit_path=False, positive=positive)

-            lars.fit(dictionary.T, X.T, Xy=cov)

-            new_code = lars.coef_

-        finally:

-            np.seterr(**err_mgt)

-

-    elif algorithm == 'threshold':

-        new_code = ((np.sign(cov) *

-                    np.maximum(np.abs(cov) - regularization, 0)).T)

-        if positive:

-            np.clip(new_code, 0, None, out=new_code)

-

-    elif algorithm == 'omp':

-        # TODO: Should verbose argument be passed to this?

-        if positive:

-            raise ValueError(

-                "Positive constraint not supported for \"omp\" coding method."

-            )

-        new_code = orthogonal_mp_gram(

-            Gram=gram, Xy=cov, n_nonzero_coefs=int(regularization),

-            tol=None, norms_squared=row_norms(X, squared=True),

-            copy_Xy=copy_cov).T

-    else:

-        raise ValueError('Sparse coding method must be "lasso_lars" '

-                         '"lasso_cd",  "lasso", "threshold" or "omp", got %s.'

-                         % algorithm)

-    if new_code.ndim != 2:

-        return new_code.reshape(n_samples, n_components)

-    return new_code

+            np.seterr(**err

 

 

 # XXX : could be moved to the linear_model module
