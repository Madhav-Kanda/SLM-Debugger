--- a/decoupled/60/0.8_0.2/205/scikit-learn_scikit-learn/sklearn/utils/estimator_checks.py
+++ b/decoupled/60/0.8_0.2/205/scikit-learn_scikit-learn/sklearn/utils/estimator_checks.py
@@ -4064,61 +4064,23 @@
     ), f"Expected {n_features_out} feature names, got {len(feature_names_out)}"

 

 

-def check_transformer_get_feature_names_out_pandas(name, transformer_orig):

-    try:

-        import pandas as pd

-    except ImportError:

-        raise SkipTest(

-            "pandas is not installed: not checking column name consistency for pandas"

-        )

-

-    tags = transformer_orig._get_tags()

-    if "2darray" not in tags["X_types"] or tags["no_validation"]:

-        return

-

-    X, y = make_blobs(

-        n_samples=30,

-        centers=[[0, 0, 0], [1, 1, 1]],

-        random_state=0,

-        n_features=2,

-        cluster_std=0.1,

-    )

-    X = StandardScaler().fit_transform(X)

-

-    transformer = clone(transformer_orig)

-    X = _enforce_estimator_tags_X(transformer, X)

-

-    n_features = X.shape[1]

-    set_random_state(transformer)

-

-    y_ = y

-    if name in CROSS_DECOMPOSITION:

-        y_ = np.c_[np.asarray(y), np.asarray(y)]

-        y_[::2, 1] *= 2

-

-    feature_names_in = [f"col{i}" for i in range(n_features)]

-    df = pd.DataFrame(X, columns=feature_names_in)

-    X_transform = transformer.fit_transform(df, y=y_)

-

-    # error is raised when `input_features` do not match feature_names_in

-    invalid_feature_names = [f"bad{i}" for i in range(n_features)]

-    with raises(ValueError, match="input_features is not equal to feature_names_in_"):

-        transformer.get_feature_names_out(invalid_feature_names)

-

-    feature_names_out_default = transformer.get_feature_names_out()

-    feature_names_in_explicit_names = transformer.get_feature_names_out(

-        feature_names_in

-    )

-    assert_array_equal(feature_names_out_default, feature_names_in_explicit_names)

-

-    if isinstance(X_transform, tuple):

-        n_features_out = X_transform[0].shape[1]

-    else:

-        n_features_out = X_transform.shape[1]

-

-    assert (

-        len(feature_names_out_default) == n_features_out

-    ), f"Expected {n_features_out} feature names, got {len(feature_names_out_default)}"

+def unique_labels(y_true, y_pred):

+    # Ensure y_true and y_pred are pandas Series

+    if not (isinstance(y_true, pd.Series) and isinstance(y_pred, pd.Series)):

+        raise ValueError("Both y_true and y_pred must be pandas Series")

+    

+    # Convert to numpy arrays, preserving dtypes

+    y_true_np = y_true.values

+    y_pred_np = y_pred.values

+    

+    # Ensure dtypes are consistent

+    if y_true_np.dtype != y_pred_np.dtype:

+        raise ValueError("Dtypes of y_true and y_pred must be the same")

+    

+    # Get unique labels

+    unique_labels = np.unique(np.concatenate((y_true_np, y_pred_np)))

+    

+    return unique_labels

 

 

 def check_param_validation(name, estimator_orig):
