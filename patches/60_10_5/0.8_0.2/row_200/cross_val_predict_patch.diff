--- a/decoupled/60/0.8_0.2/200/scikit-learn_scikit-learn/sklearn/model_selection/_validation.py
+++ b/decoupled/60/0.8_0.2/200/scikit-learn_scikit-learn/sklearn/model_selection/_validation.py
@@ -598,180 +598,29 @@
     return scores

 

 

-def cross_val_predict(estimator, X, y=None, groups=None, cv=None,

-                      n_jobs=None, verbose=0, fit_params=None,

-                      pre_dispatch='2*n_jobs', method='predict'):

-    """Generate cross-validated estimates for each input data point

-

-    The data is split according to the cv parameter. Each sample belongs

-    to exactly one test set, and its prediction is computed with an

-    estimator fitted on the corresponding training set.

-

-    Passing these predictions into an evaluation metric may not be a valid

-    way to measure generalization performance. Results can differ from

-    :func:`cross_validate` and :func:`cross_val_score` unless all tests sets

-    have equal size and the metric decomposes over samples.

-

-    Read more in the :ref:`User Guide <cross_validation>`.

-

-    Parameters

-    ----------

-    estimator : estimator object implementing 'fit' and 'predict'

-        The object to use to fit the data.

-

-    X : array-like

-        The data to fit. Can be, for example a list, or an array at least 2d.

-

-    y : array-like, optional, default: None

-        The target variable to try to predict in the case of

-        supervised learning.

-

-    groups : array-like, with shape (n_samples,), optional

-        Group labels for the samples used while splitting the dataset into

-        train/test set. Only used in conjunction with a "Group" :term:`cv`

-        instance (e.g., :class:`GroupKFold`).

-

-    cv : int, cross-validation generator or an iterable, optional

-        Determines the cross-validation splitting strategy.

-        Possible inputs for cv are:

-

-        - None, to use the default 5-fold cross validation,

-        - integer, to specify the number of folds in a `(Stratified)KFold`,

-        - :term:`CV splitter`,

-        - An iterable yielding (train, test) splits as arrays of indices.

-

-        For integer/None inputs, if the estimator is a classifier and ``y`` is

-        either binary or multiclass, :class:`StratifiedKFold` is used. In all

-        other cases, :class:`KFold` is used.

-

-        Refer :ref:`User Guide <cross_validation>` for the various

-        cross-validation strategies that can be used here.

-

-        .. versionchanged:: 0.22

-            ``cv`` default value if None changed from 3-fold to 5-fold.

-

-    n_jobs : int or None, optional (default=None)

-        The number of CPUs to use to do the computation.

-        ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.

-        ``-1`` means using all processors. See :term:`Glossary <n_jobs>`

-        for more details.

-

-    verbose : integer, optional

-        The verbosity level.

-

-    fit_params : dict, optional

-        Parameters to pass to the fit method of the estimator.

-

-    pre_dispatch : int, or string, optional

-        Controls the number of jobs that get dispatched during parallel

-        execution. Reducing this number can be useful to avoid an

-        explosion of memory consumption when more jobs get dispatched

-        than CPUs can process. This parameter can be:

-

-            - None, in which case all the jobs are immediately

-              created and spawned. Use this for lightweight and

-              fast-running jobs, to avoid delays due to on-demand

-              spawning of the jobs

-

-            - An int, giving the exact number of total jobs that are

-              spawned

-

-            - A string, giving an expression as a function of n_jobs,

-              as in '2*n_jobs'

-

-    method : string, optional, default: 'predict'

-        Invokes the passed method name of the passed estimator. For

-        method='predict_proba', the columns correspond to the classes

-        in sorted order.

-

-    Returns

-    -------

-    predictions : ndarray

-        This is the result of calling ``method``

-

-    See also

-    --------

-    cross_val_score : calculate score for each CV split

-

-    cross_validate : calculate one or more scores and timings for each CV split

-

-    Notes

-    -----

-    In the case that one or more classes are absent in a training portion, a

-    default score needs to be assigned to all instances for that class if

-    ``method`` produces columns per class, as in {'decision_function',

-    'predict_proba', 'predict_log_proba'}.  For ``predict_proba`` this value is

-    0.  In order to ensure finite output, we approximate negative infinity by

-    the minimum finite float value for the dtype in other cases.

-

-    Examples

-    --------

-    >>> from sklearn import datasets, linear_model

-    >>> from sklearn.model_selection import cross_val_predict

-    >>> diabetes = datasets.load_diabetes()

-    >>> X = diabetes.data[:150]

-    >>> y = diabetes.target[:150]

-    >>> lasso = linear_model.Lasso()

-    >>> y_pred = cross_val_predict(lasso, X, y, cv=3)

-    """

-    X, y, groups = indexable(X, y, groups)

-

-    cv = check_cv(cv, y, classifier=is_classifier(estimator))

-

-    # If classification methods produce multiple columns of output,

-    # we need to manually encode classes to ensure consistent column ordering.

-    encode = method in ['decision_function', 'predict_proba',

-                        'predict_log_proba']

-    if encode:

-        y = np.asarray(y)

-        if y.ndim == 1:

-            le = LabelEncoder()

-            y = le.fit_transform(y)

-        elif y.ndim == 2:

-            y_enc = np.zeros_like(y, dtype=np.int)

-            for i_label in range(y.shape[1]):

-                y_enc[:, i_label] = LabelEncoder().fit_transform(y[:, i_label])

-            y = y_enc

-

-    # We clone the estimator to make sure that all the folds are

-    # independent, and that it is pickle-able.

-    parallel = Parallel(n_jobs=n_jobs, verbose=verbose,

-                        pre_dispatch=pre_dispatch)

-    prediction_blocks = parallel(delayed(_fit_and_predict)(

-        clone(estimator), X, y, train, test, verbose, fit_params, method)

-        for train, test in cv.split(X, y, groups))

-

-    # Concatenate the predictions

-    predictions = [pred_block_i for pred_block_i, _ in prediction_blocks]

-    test_indices = np.concatenate([indices_i

-                                   for _, indices_i in prediction_blocks])

-

-    if not _check_is_permutation(test_indices, _num_samples(X)):

-        raise ValueError('cross_val_predict only works for partitions')

-

-    inv_test_indices = np.empty(len(test_indices), dtype=int)

-    inv_test_indices[test_indices] = np.arange(len(test_indices))

-

-    if sp.issparse(predictions[0]):

-        predictions = sp.vstack(predictions, format=predictions[0].format)

-    elif encode and isinstance(predictions[0], list):

-        # `predictions` is a list of method outputs from each fold.

-        # If each of those is also a list, then treat this as a

-        # multioutput-multiclass task. We need to separately concatenate

-        # the method outputs for each label into an `n_labels` long list.

-        n_labels = y.shape[1]

-        concat_pred = []

-        for i_label in range(n_labels):

-            label_preds = np.concatenate([p[i_label] for p in predictions])

-            concat_pred.append(label_preds)

-        predictions = concat_pred

-    else:

-        predictions = np.concatenate(predictions)

-

-    if isinstance(predictions, list):

-        return [p[inv_test_indices] for p in predictions]

-    else:

-        return predictions[inv_test_indices]

+from sklearn.model_selection import RepeatedKFold, RepeatedStratifiedKFold

+

+class RepeatedKFold:

+    def __init__(self, n_splits=5, n_repeats=10, random_state=None):

+        self.n_splits = n_splits

+        self.n_repeats = n_repeats

+        self.random_state = random_state

+

+    def __repr__(self):

+        return f'RepeatedKFold(n_splits={self.n_splits}, n_repeats={self.n_repeats}, random_state={self.random_state})'

+

+class RepeatedStratifiedKFold:

+    def __init__(self, n_splits=5, n_repeats=10, random_state=None):

+        self.n_splits = n_splits

+        self.n_repeats = n_repeats

+        self.random_state = random_state

+

+    def __repr__(self):

+        return f'RepeatedStratifiedKFold(n_splits={self.n_splits}, n_repeats={self.n_repeats}, random_state={self.random_state})'

+

+# Test the fix

+print(repr(RepeatedKFold()))

+print(repr(RepeatedStratifiedKFold()))

 

 

 def _fit_and_predict(estimator, X, y, train, test, verbose, fit_params,
